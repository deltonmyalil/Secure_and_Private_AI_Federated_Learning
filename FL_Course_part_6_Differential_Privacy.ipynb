{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL_Course_part_6_Differential_Privacy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKZx7UNDVc5nM/SqQUt9D+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "emmb0NZdiKBE"
      },
      "source": [
        "!pip install syft==0.2.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpfalDNQifPe"
      },
      "source": [
        "# Differential Privacy example for a single feature database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjkJPh-0jbml"
      },
      "source": [
        "Single boolean column of random 1 or 0. 5000 rows. Initialize a random list of 1s and 0s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xrFAjajjr-A",
        "outputId": "a5b39cef-521e-4a28-988e-765857cca36d"
      },
      "source": [
        "import torch\r\n",
        "num_entries = 5000\r\n",
        "\r\n",
        "db = torch.rand(num_entries).gt(0.5).to(torch.uint8)\r\n",
        "db"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1,  ..., 1, 1, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtTvErw1lLb6"
      },
      "source": [
        "Key to the definition of differenital privacy is the ability to ask the question \"When querying a database, if I removed someone from the database, would the output of the query be any different?\". Thus, in order to check this, we must construct what we term \"parallel databases\" which are simply databases with one entry removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaowxJiElNty"
      },
      "source": [
        "Create 5000 parallel databases where in each of the database, one entry from the original database is dropped. Hence the size of each of the parallel databases will be 4999.\r\n",
        "\r\n",
        "To do this, to delete element at index i, we slice the db from 0 to i, another slice at i+1 to 5000. Then concat these two slices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNLoNU_NlmHv"
      },
      "source": [
        "def get_parallel_db(db, remove_index):\r\n",
        "    return torch.cat((db[0:remove_index], db[remove_index+1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji4JxlFUogIN",
        "outputId": "e4864490-8036-4113-e726-9f75a1c27ae4"
      },
      "source": [
        "get_parallel_db(db, 3).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSyZ5cwMoi-O"
      },
      "source": [
        "def get_parallel_dbs(db):\r\n",
        "    parallel_dbs = list()\r\n",
        "    for i in range(len(db)):\r\n",
        "        pdb = get_parallel_db(db, i)\r\n",
        "        parallel_dbs.append(pdb)\r\n",
        "    return parallel_dbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaRXDdhqp_h4"
      },
      "source": [
        "pdbs = get_parallel_dbs(db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Ek8aWQqPwO"
      },
      "source": [
        "# Convenience function to do all these\r\n",
        "def create_db_and_parallels(num_entries):\r\n",
        "   \r\n",
        "    def get_parallel_dbs(db):\r\n",
        "        \r\n",
        "        def get_parallel_db(db, remove_index):\r\n",
        "            return torch.cat((db[0:remove_index], db[remove_index+1:]))\r\n",
        "\r\n",
        "        parallel_dbs = list()\r\n",
        "        for i in range(len(db)):\r\n",
        "            pdb = get_parallel_db(db, i)\r\n",
        "            parallel_dbs.append(pdb)\r\n",
        "        return parallel_dbs\r\n",
        "\r\n",
        "    db = torch.rand(num_entries).gt(0.5).to(torch.uint8)\r\n",
        "    pdbs = get_parallel_dbs(db)\r\n",
        "    return db, pdbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUbbLVLorP35"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-C66vhcrUzw",
        "outputId": "79655555-43b3-4fe9-859d-3ca1e19a0e44"
      },
      "source": [
        "db.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dqwo4kDrV68",
        "outputId": "95e60296-a2c4-4994-b9b1-71599e8b451f"
      },
      "source": [
        "len(pdbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23t9RyWtraJ_",
        "outputId": "546131d3-57ae-40ad-c97b-7fb0b553749d"
      },
      "source": [
        "pdbs[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwwGMq6frecS",
        "outputId": "d1ab0fba-a9f2-42ca-e189-ea7b3b1ec508"
      },
      "source": [
        "pdbs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        dtype=torch.uint8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNPPf4BrjU3"
      },
      "source": [
        "## Evaluating the Privacy of a Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIYPKk_r8wi5",
        "outputId": "3ad532ce-0f38-456d-82e9-fb922ae445cf"
      },
      "source": [
        "db, pdb = create_db_and_parallels(20)\r\n",
        "db"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdIzftaB-HyY",
        "outputId": "bf6ff722-92bf-4a39-e99a-373f9f85c943"
      },
      "source": [
        "len(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA_XZ6Ri-Klw",
        "outputId": "b0117788-175c-4fa5-97ef-b11789195300"
      },
      "source": [
        "len(pdb[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHD7036g-UB9"
      },
      "source": [
        "Create a function that queries this database. Let the query be a simple sum ie for a binary vector, it is the number of ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZOq4WU7-ixk",
        "outputId": "dbfcaf90-1dac-44dc-ed14-2da795938c7e"
      },
      "source": [
        "def query(db):\r\n",
        "    return db.sum()\r\n",
        "\r\n",
        "query(db).item() # item() to return number, Otherwise it will return tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LkD0rcT-xru"
      },
      "source": [
        "So, the actual sum is 11. For the parallel databases, with one guy removed, the output of this query gets changed. Shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHzPsGIB_P_N",
        "outputId": "90fbbd64-58dd-48f8-d503-531c9e557b83"
      },
      "source": [
        "print([query(temp_db).item() for temp_db in pdb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11, 10, 10, 10, 10, 11, 10, 10, 11, 11, 10, 10, 11, 10, 10, 11, 11, 11, 11, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3e3RQm_hQZ"
      },
      "source": [
        "We need to find the max distance with which the parallel dbs change when you apply the query function on them compared to the application of the query function to the actual db."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caRk0hvXAahK"
      },
      "source": [
        "max_distance = 0\r\n",
        "centralized_db_result = query(db) # returns torch.Tensor\r\n",
        "for temp_db in pdb:\r\n",
        "    temp_db_result = query(temp_db) # returns torch.Tensor\r\n",
        "    db_l1_distance = torch.abs(temp_db_result - centralized_db_result)\r\n",
        "    if db_l1_distance > max_distance: max_distance = db_l1_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_07a06QqBV6f",
        "outputId": "f8e62381-468d-4261-9fdf-d98b3d3b4fce"
      },
      "source": [
        "max_distance.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlmqWK2pBXVs"
      },
      "source": [
        "This is called sensitivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U860gd49D9qX"
      },
      "source": [
        "### Sensitivity:\r\n",
        "\r\n",
        "The maximum amount by which the query changes when removing an individual from the data.\r\n",
        "\r\n",
        "It is also called the L1-Sensitivity.\r\n",
        "\r\n",
        "Now we found how to find the sensitivity of the function sum(). Now onwards to finding the sensitivity of any function generically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWv7n9vDEQsD",
        "outputId": "95fa0b61-18fe-49e1-e4b6-ea5bb492ec5e"
      },
      "source": [
        "def calculate_sensitivity(query, num_entries, verbose=False):\r\n",
        "    def create_db_and_parallels(num_entries):\r\n",
        "    \r\n",
        "        def get_parallel_dbs(db):\r\n",
        "            \r\n",
        "            def get_parallel_db(db, remove_index):\r\n",
        "                return torch.cat((db[0:remove_index], db[remove_index+1:]))\r\n",
        "\r\n",
        "            parallel_dbs = list()\r\n",
        "            for i in range(len(db)):\r\n",
        "                pdb = get_parallel_db(db, i)\r\n",
        "                parallel_dbs.append(pdb)\r\n",
        "            return parallel_dbs\r\n",
        "\r\n",
        "        db = torch.rand(num_entries).gt(0.5).to(torch.uint8)\r\n",
        "        pdbs = get_parallel_dbs(db)\r\n",
        "        return db, pdbs\r\n",
        "\r\n",
        "    db, pdbs = create_db_and_parallels(num_entries)\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "        print('Centralized data is: ', db)\r\n",
        "        print('Parallel data are: ', pdbs)\r\n",
        "\r\n",
        "    centralized_result = query(db)\r\n",
        "    parallel_results = [query(temp_db) for temp_db in pdbs]\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "        print('Centralized result: ', centralized_result)\r\n",
        "        print('Parallel results: ', parallel_results)\r\n",
        "\r\n",
        "    max_distance = 0\r\n",
        "    for parallel_result in parallel_results:\r\n",
        "        if max_distance < torch.abs(centralized_result - parallel_result): \r\n",
        "            max_distance = torch.abs(centralized_result - parallel_result)\r\n",
        "    L1_sensitivity = max_distance\r\n",
        "    return L1_sensitivity\r\n",
        "\r\n",
        "print('Sensitivity for sum function is: ', calculate_sensitivity(lambda x: x.sum(), 20, verbose=True).item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Centralized data is:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
            "       dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
            "       dtype=torch.uint8)]\n",
            "Centralized result:  tensor(10)\n",
            "Parallel results:  [tensor(10), tensor(10), tensor(9), tensor(9), tensor(9), tensor(10), tensor(9), tensor(9), tensor(10), tensor(9), tensor(10), tensor(9), tensor(9), tensor(10), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10)]\n",
            "Sensitivity for sum function is:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYUt2y6XEsUn"
      },
      "source": [
        "What happens if the query function is to find the mean? What will the removal of one element from the database result in?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gon4pMVMjbOa",
        "outputId": "1494d1f2-4750-4e24-ae9f-453a83f0a0c7"
      },
      "source": [
        "print([temp_db.float().mean() for temp_db in pdbs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.4211), tensor(0.4211), tensor(0.4737), tensor(0.4737), tensor(0.4211), tensor(0.4737), tensor(0.4211), tensor(0.4737), tensor(0.4737), tensor(0.4211), tensor(0.4211), tensor(0.4211), tensor(0.4737), tensor(0.4737), tensor(0.4737), tensor(0.4211), tensor(0.4211), tensor(0.4737), tensor(0.4737), tensor(0.4737)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiPxPOZJjewT",
        "outputId": "18e2b5df-9889-4697-c484-a9671ad2b6c1"
      },
      "source": [
        "# mean query\r\n",
        "# or use lambda x: x.float().mean() instead\r\n",
        "def mean_query(db):\r\n",
        "    return db.float().mean()\r\n",
        "\r\n",
        "for _ in range(10): print(\"Sensitivity for the query mean is: \", calculate_sensitivity(mean_query, 200).item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity for the query mean is:  0.0026633143424987793\n",
            "Sensitivity for the query mean is:  0.0025628209114074707\n",
            "Sensitivity for the query mean is:  0.002914607524871826\n",
            "Sensitivity for the query mean is:  0.0026884078979492188\n",
            "Sensitivity for the query mean is:  0.002613067626953125\n",
            "Sensitivity for the query mean is:  0.0026884078979492188\n",
            "Sensitivity for the query mean is:  0.0027889609336853027\n",
            "Sensitivity for the query mean is:  0.0025628209114074707\n",
            "Sensitivity for the query mean is:  0.0027889609336853027\n",
            "Sensitivity for the query mean is:  0.0026884078979492188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGMoPH9Hkkbj",
        "outputId": "e724b3db-0861-45a3-d67a-a4298138c3a0"
      },
      "source": [
        "from statistics import mean\r\n",
        "sensitivities = []\r\n",
        "for _ in range(100):\r\n",
        "    sensitivities.append(calculate_sensitivity(mean_query, 200).item())\r\n",
        "mean(sensitivities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026711082458496095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph7BL2tFlAMc"
      },
      "source": [
        "This will result in an average sensitivity that is the same as the average value / num_entries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9DXYhYVlpRh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc-skUfRDugK"
      },
      "source": [
        "## Calculate the L1-Sensitivity of Threshold Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S0rpB5oD-Yb"
      },
      "source": [
        "Compute the sum over the database and return whether the sum is greater than a certain threshold.\r\n",
        "\r\n",
        "Then create a database of size 10 and calculate the sensitivity for the threshold function\r\n",
        "\r\n",
        "Reinitialize the DB 10 times and find the sensitivity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv1fsUeYEeDr",
        "outputId": "34c217e1-5d76-4083-ef98-55c1ed58d416"
      },
      "source": [
        "def query(db, threshold=5):\r\n",
        "    return (db.sum() > threshold).float()\r\n",
        "\r\n",
        "db, pdbs = create_db_and_parallels(10)\r\n",
        "\r\n",
        "print('Sum of db: ', db.sum())\r\n",
        "for pdb in pdbs: print('Sum: ', pdb.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sum of db:  tensor(7)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(7)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(7)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(7)\n",
            "Sum:  tensor(6)\n",
            "Sum:  tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJwp2tyZGJMi",
        "outputId": "cc53b1d2-050e-44cb-c572-d3b6868f0ea6"
      },
      "source": [
        "for pdb in pdbs: print('Threshold for 5 is:', query(pdb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n",
            "Threshold for 5 is: tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z8fVLq4GjYa",
        "outputId": "ae61046e-fa68-4826-c449-77224366559a"
      },
      "source": [
        "for _ in range(5):\r\n",
        "    calculate_sensitivity(query, num_entries=10, verbose=True)\r\n",
        "    print('=========================================================================================================================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Centralized data is:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0], dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([1, 1, 0, 1, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 0, 1, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 0, 1, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 1, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 1, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 1, 0, 0, 1, 0], dtype=torch.uint8), tensor([0, 1, 1, 0, 1, 0, 0, 1, 0], dtype=torch.uint8)]\n",
            "Centralized result:  tensor(0.)\n",
            "Parallel results:  [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "=========================================================================================================================\n",
            "Centralized data is:  tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([0, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8)]\n",
            "Centralized result:  tensor(0.)\n",
            "Parallel results:  [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "=========================================================================================================================\n",
            "Centralized data is:  tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1], dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([0, 1, 0, 1, 0, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 0, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 0, 1, 0, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 1, 0, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 0, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1], dtype=torch.uint8), tensor([1, 0, 1, 0, 1, 0, 0, 0, 0], dtype=torch.uint8)]\n",
            "Centralized result:  tensor(0.)\n",
            "Parallel results:  [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "=========================================================================================================================\n",
            "Centralized data is:  tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([1, 0, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 0, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 1, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 0, 0, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 0, 1, 0, 1, 0], dtype=torch.uint8), tensor([1, 1, 0, 0, 0, 1, 0, 1, 0], dtype=torch.uint8)]\n",
            "Centralized result:  tensor(0.)\n",
            "Parallel results:  [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "=========================================================================================================================\n",
            "Centralized data is:  tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1], dtype=torch.uint8)\n",
            "Parallel data are:  [tensor([1, 0, 1, 1, 0, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 0, 1, 1, 0, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 1, 1, 0, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 0, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 0, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 1, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 1, 0, 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 1, 0, 0, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 1, 0, 0, 1, 1], dtype=torch.uint8), tensor([1, 1, 0, 1, 1, 0, 0, 1, 1], dtype=torch.uint8)]\n",
            "Centralized result:  tensor(1.)\n",
            "Parallel results:  [tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.)]\n",
            "=========================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmIKrBDbHGMC"
      },
      "source": [
        "Sensitivity is variable here and depends on the sum.. In turn the elements in the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1W3_m8OHRIa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}