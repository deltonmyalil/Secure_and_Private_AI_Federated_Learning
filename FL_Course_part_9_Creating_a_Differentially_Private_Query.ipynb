{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL_Course_part_9_Creating_a_Differentially_Private_Query.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUfgmfFmHgtG7Cs01mze4g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VojBubFMVFx3"
      },
      "source": [
        "Create a query function that sums over the database and adds just the right amount of noise such that it satisfies the epsilon constraint for laplacian noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO-CrF9NVflR",
        "outputId": "39faf9ce-fd52-425b-b73a-ccf57f937950"
      },
      "source": [
        "!pip install syft==0.2.9 >/dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= \"3.0\", but you'll have notebook 5.7.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.1.1 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0qumjPVlEA"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "\r\n",
        "class CalculateSensitivity:\r\n",
        "    \"This is a class that contains reusable methods for initializing parallel dbs \\\r\n",
        "with number of entries. Use classObject.create_db_and_parallels(num_entries) to \\\r\n",
        "get db and parallel db list. Use classObject.sensitivity(query, num_entries, verbose) \\\r\n",
        "to find the sensitivity of the query function\"\r\n",
        "\r\n",
        "    def get_parallel_db(self, db, remove_index):\r\n",
        "        return torch.cat((db[0:remove_index], db[remove_index+1:]))\r\n",
        "\r\n",
        "    def get_parallel_dbs(self, db):\r\n",
        "        parallel_dbs = list()\r\n",
        "        for i in range(len(db)):\r\n",
        "            pdb = self.get_parallel_db(db, i)\r\n",
        "            parallel_dbs.append(pdb)\r\n",
        "        return parallel_dbs\r\n",
        "\r\n",
        "    def create_db_and_parallels(self, num_entries):\r\n",
        "        db = torch.rand(num_entries).gt(0.5).to(torch.uint8)\r\n",
        "        pdbs = self.get_parallel_dbs(db)\r\n",
        "        return db, pdbs\r\n",
        "\r\n",
        "    def sensitivity(self, query, num_entries, verbose):\r\n",
        "\r\n",
        "        db, pdbs = self.create_db_and_parallels(num_entries)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print('Centralized data is: ', db)\r\n",
        "            print('Parallel data are: ', pdbs)\r\n",
        "\r\n",
        "        centralized_result = query(db)\r\n",
        "        parallel_results = [query(temp_db) for temp_db in pdbs]\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print('Centralized result: ', centralized_result)\r\n",
        "            print('Parallel results: ', parallel_results)\r\n",
        "\r\n",
        "        max_distance = 0\r\n",
        "        for parallel_result in parallel_results:\r\n",
        "            if max_distance < torch.abs(centralized_result - parallel_result): \r\n",
        "                max_distance = torch.abs(centralized_result - parallel_result)\r\n",
        "        L1_sensitivity = max_distance\r\n",
        "        return L1_sensitivity\r\n",
        "\r\n",
        "helper = CalculateSensitivity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H4rlCEiXRVN",
        "outputId": "e7b40a65-3d2d-451e-b74e-8c45da0e7513"
      },
      "source": [
        "\r\n",
        "epsilon = 0.5\r\n",
        "\r\n",
        "db, pdbs = helper.create_db_and_parallels(num_entries=100)\r\n",
        "\r\n",
        "sum(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(52, dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuvYlEMsXdjL",
        "outputId": "f81bcc4d-975e-485b-c1c8-709d33d5fda4"
      },
      "source": [
        "def sum_query(db):\r\n",
        "    return db.sum()\r\n",
        "\r\n",
        "def laplacian_mechanism(db, query, sensitivity):\r\n",
        "    beta = sensitivity / epsilon\r\n",
        "    noise = torch.tensor(np.random.laplace(0, beta, 1))\r\n",
        "    return query(db) + noise # Global DP\r\n",
        "\r\n",
        "# Sum query's sensitivity is 1 as for a binary array, the maximum change that can be made by removing an element is by 1\r\n",
        "laplacian_mechanism(db, sum_query, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([52.0594], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJCuHqZ3YORE",
        "outputId": "6fa9fb1e-dd83-4339-a821-30721275f495"
      },
      "source": [
        "# True query return\r\n",
        "sum_query(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(52)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xu2Oh1iYiFj"
      },
      "source": [
        "That's pretty close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_ccatBvYlNz"
      },
      "source": [
        "Doing the same for mean query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QKR7QpaYn8u"
      },
      "source": [
        "def mean_query(db):\r\n",
        "    return torch.mean(db.float())\r\n",
        "\r\n",
        "# The sensitivity of this query is 1/100. That is the maximum amount by which the sum can change divided\r\n",
        "# by the total number of numbers in the db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGoblNXjY6Sd",
        "outputId": "7eaaea33-8603-43f3-979a-1a8709d9d30f"
      },
      "source": [
        "# laplacian mechanism on mean query\r\n",
        "laplacian_mechanism(db, mean_query, 1/100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5079], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4pWyXSZZM3y",
        "outputId": "a31f61c2-aa5a-4b04-cfce-576f086ddc9c"
      },
      "source": [
        "mean_query(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMSLxnoMZRMa"
      },
      "source": [
        "Lower values of epsilon like 0.0001 etc will have a negative impact on the query's output as it will add too much noise. ie beta for laplace = sensitivity / epsilon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Ymri67ZvwM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}