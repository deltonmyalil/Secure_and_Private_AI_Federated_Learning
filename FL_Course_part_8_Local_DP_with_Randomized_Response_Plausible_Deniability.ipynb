{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL_Course_part_8_Local_DP_with_Randomized_Response_Plausible_Deniability.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPi9JpmknmCIyRkuGGGjNX9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbfgre9GoezU"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTDlnPVnisE"
      },
      "source": [
        "!pip install syft==0.2.9 >/dev/null"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q51cs9faodpk"
      },
      "source": [
        "# Local and Global Differential Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lByRnIpai9"
      },
      "source": [
        "### Local DB\r\n",
        "\r\n",
        "* Adding noise directly to the database or having individuals add noise to their own data before putting it into the database.\r\n",
        "\r\n",
        "* Protection is happening at a local level.\r\n",
        "\r\n",
        "###Global DP\r\n",
        "\r\n",
        "* Adds noise to the output of the query to the database\r\n",
        "\r\n",
        "* More accurate results to the query\r\n",
        "\r\n",
        "* But requires the DB administrator or central server to be trustworthy.\r\n",
        "\r\n",
        "\r\n",
        "## How much Noise should be added\r\n",
        "### Randomized Response:\r\n",
        "https://www.youtube.com/watch?v=0QuwEoesV9Q\r\n",
        "\r\n",
        "Added privacy comes at the cost of accuracy.\r\n",
        "\r\n",
        "### Goal of Differential Privacy:\r\n",
        "* How to get the most accurate results with the greatest amount of privacy.\r\n",
        "* Greatest fit with trust models in the actual world - flexible DP strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpnCSUGLrjw3"
      },
      "source": [
        "### Implementing Randomized Response using Plausible Deniability\r\n",
        "\r\n",
        "* Flip coins using a binary rand generator\r\n",
        "* For each entry in the DB, flip two coins\r\n",
        "* If the first coin is Heads, leave the entry in the DB as it is. If it is Tails, reset that entry in the DB w.r.t. the second coin flip.\r\n",
        "* Then, perform a query on the original DB and on the modified DB according to the coin flips\r\n",
        "* Perform the mean query on both these DB\r\n",
        "* Study how much the noise changes w.r.t the size of the DB.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRl-mkEBsiym"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "class CalculateSensitivity:\r\n",
        "    \"This is a class that contains reusable methods for initializing parallel dbs \\\r\n",
        "with number of entries. Use classObject.create_db_and_parallels(num_entries) to \\\r\n",
        "get db and parallel db list. Use classObject.sensitivity(query, num_entries, verbose) \\\r\n",
        "to find the sensitivity of the query function\"\r\n",
        "\r\n",
        "    def get_parallel_db(self, db, remove_index):\r\n",
        "        return torch.cat((db[0:remove_index], db[remove_index+1:]))\r\n",
        "\r\n",
        "    def get_parallel_dbs(self, db):\r\n",
        "        parallel_dbs = list()\r\n",
        "        for i in range(len(db)):\r\n",
        "            pdb = self.get_parallel_db(db, i)\r\n",
        "            parallel_dbs.append(pdb)\r\n",
        "        return parallel_dbs\r\n",
        "\r\n",
        "    def create_db_and_parallels(self, num_entries):\r\n",
        "        db = torch.rand(num_entries).gt(0.5).to(torch.uint8)\r\n",
        "        pdbs = self.get_parallel_dbs(db)\r\n",
        "        return db, pdbs\r\n",
        "\r\n",
        "    def sensitivity(self, query, num_entries, verbose):\r\n",
        "\r\n",
        "        db, pdbs = self.create_db_and_parallels(num_entries)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print('Centralized data is: ', db)\r\n",
        "            print('Parallel data are: ', pdbs)\r\n",
        "\r\n",
        "        centralized_result = query(db)\r\n",
        "        parallel_results = [query(temp_db) for temp_db in pdbs]\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print('Centralized result: ', centralized_result)\r\n",
        "            print('Parallel results: ', parallel_results)\r\n",
        "\r\n",
        "        max_distance = 0\r\n",
        "        for parallel_result in parallel_results:\r\n",
        "            if max_distance < torch.abs(centralized_result - parallel_result): \r\n",
        "                max_distance = torch.abs(centralized_result - parallel_result)\r\n",
        "        L1_sensitivity = max_distance\r\n",
        "        return L1_sensitivity\r\n",
        "\r\n",
        "# sens = CalculateSensitivity()\r\n",
        "# sens.sensitivity(lambda x:x.sum(), num_entries=10, verbose=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "mtqv0ulZuZvH",
        "outputId": "e15cef6d-221c-44e4-dcfe-3b008de55c9a"
      },
      "source": [
        "helper = CalculateSensitivity()\r\n",
        "helper.__doc__"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This is a class that contains reusable methods for initializing parallel dbs with number of entries. Use classObject.create_db_and_parallels(num_entries) to get db and parallel db list. Use classObject.sensitivity(query, num_entries, verbose) to find the sensitivity of the query function'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T5M8mE7uiKl",
        "outputId": "076be63d-2269-4f8b-b1e7-913b67b2a5cb"
      },
      "source": [
        "db, pdbs = helper.create_db_and_parallels(num_entries=100)\r\n",
        "db"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        0, 0, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlBRXV6uuul2",
        "outputId": "a6e4ad1e-18de-48cc-8471-0c251dd9c084"
      },
      "source": [
        "true_result = torch.mean(db.float()); true_result"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W08q_67u5Cm",
        "outputId": "315464e2-3eb5-4139-f0ef-b44057b6163d"
      },
      "source": [
        "# .float() used to convert boolean tensor to float tensor\r\n",
        "first_coin_flip = (torch.rand(len(db)) > 0.5).float()\r\n",
        "first_coin_flip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
              "        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
              "        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muDCqY4vZzW",
        "outputId": "7d4507a8-8b5b-4c5d-f9b7-67f6b3328afc"
      },
      "source": [
        "second_coin_flip = (torch.rand(len(db)) > 0.5).float()\r\n",
        "second_coin_flip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
              "        0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmpd6imQv3Zu",
        "outputId": "ba2ca8db-25dc-436e-9439-15f4e448e265"
      },
      "source": [
        "# If first coin flip is 1, keep the original value in db. If it is 0, keep the value in second coin flip\r\n",
        "augmented_db = []\r\n",
        "for value, first_coin, second_coin in zip(db.float(), first_coin_flip, second_coin_flip):\r\n",
        "\r\n",
        "    if first_coin.item() == 1.0:\r\n",
        "        augmented_db.append(value.item())\r\n",
        "    else:\r\n",
        "        augmented_db.append(second_coin.item())\r\n",
        "torch.FloatTensor(augmented_db)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNVKskoXwvTl",
        "outputId": "5be71bd8-10ad-445c-ce0e-55570cb9fab0"
      },
      "source": [
        "# Smarter way to do it from Andrew Trask\r\n",
        "augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip #  HOLY SHIT!\r\n",
        "augmented_database"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1OUoL75yskz"
      },
      "source": [
        "### So creating a db, masking with local differential privacy and evaluating with mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goYoGPE6zEr8"
      },
      "source": [
        "num_entries = 100\r\n",
        "db, _ = helper.create_db_and_parallels(num_entries=num_entries)\r\n",
        "\r\n",
        "def randomized_response(db):\r\n",
        "    num_entries = len(db)\r\n",
        "    first_coin_flip = (torch.rand(num_entries) > 0.5).float()\r\n",
        "    second_coin_flip = (torch.rand(num_entries) > 0.5).float()\r\n",
        "    return db.float() * first_coin_flip + (1-first_coin_flip) * second_coin_flip\r\n",
        "\r\n",
        "augmented_database = randomized_response(db) # already FloatTensor"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsEr31S_0UNF",
        "outputId": "cb96e23b-b0c9-4618-b648-3ac99ab5267b"
      },
      "source": [
        "true_result = torch.mean(db.float())\r\n",
        "augmented_result = torch.mean(augmented_database)\r\n",
        "[true_result, augmented_result]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.5400), tensor(0.4700)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m0dIE-x0gRs",
        "outputId": "83bafbe5-b424-43e0-9882-9ed05245faab"
      },
      "source": [
        "# Creating experiment function to try with multiple num_entries\r\n",
        "\r\n",
        "def local_differential_privacy_exp(num_entries):\r\n",
        "    \"returns tuple (true result, augmented result) with respect to mean\"\r\n",
        "    db, _ = helper.create_db_and_parallels(num_entries)\r\n",
        "    augmented_database = randomized_response(db)\r\n",
        "    return (torch.mean(db.float()), torch.mean(augmented_database))\r\n",
        "\r\n",
        "local_differential_privacy_exp(100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4900), tensor(0.4500))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joF0xrrU1wIT",
        "outputId": "abc812b4-48a1-46e3-e390-3148f027b4ed"
      },
      "source": [
        "db_sizes = (10, 100, 1000, 10000, 100000)\r\n",
        "for db_size in db_sizes:\r\n",
        "    print(local_differential_privacy_exp(db_size))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor(0.4000), tensor(0.3000))\n",
            "(tensor(0.5500), tensor(0.5300))\n",
            "(tensor(0.5000), tensor(0.5100))\n",
            "(tensor(0.5064), tensor(0.5011))\n",
            "(tensor(0.4988), tensor(0.4989))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoLzsMeG1z-j"
      },
      "source": [
        "### So as the number of items in the DB increases, the accuracy will also increase for a fixed level of privacy despite the added noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAORwpvp2lmE"
      },
      "source": [
        "* Local differential privacy is data hungry and will only work well in terms of accuracy if the database is large.\r\n",
        "* If you want privacy but have less data, it will be better to add noise to the output of the query rather than to the data itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c6at9WR4NKz"
      },
      "source": [
        "## How to understand such a result:\r\n",
        "Suppose you get the mean as .6, then you can infer that the actual mean is .7 as the mean of .5(coin flip prob) and x is .6(result from query on DP data).\r\n",
        "\r\n",
        "Solving\r\n",
        "\r\n",
        "(.5+x)/2 = .6\r\n",
        "\r\n",
        ".5 + x = 1.2\r\n",
        "\r\n",
        "x = .7\r\n",
        "\r\n",
        "Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained.\r\n",
        "\r\n",
        "## Think of it this way\r\n",
        "True distribution's mean is say .7, ie 70% of the people said yes\r\n",
        "\r\n",
        "Our custom noise distribution's mean is 0.5, ie coin flip \r\n",
        "\r\n",
        "Then the resultant augmented distribution's mean will be the average of True and custom distribution ie avg(0.7, 0.5) which is 0.6. Hence if the result of the augmented query is 0.6, then we should reskew the result to get 0.7 by using 0.6(augmented result) * 2 - 0.5 (noise mean). Same is done on my query function below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "058yROGLDPWK"
      },
      "source": [
        "## Varying the Amount of Randomness/noise\r\n",
        "In other words, change the probability of the coin flip. Then also balance the result of the query to the DP dataset such that we get a correct result, which is the same as what we would have gotten if we gave the query to a non DP dataset..\r\n",
        "\r\n",
        "Augment the query to allow for varying amount of noise added to the dataset. Then bias the coin flip and make the dataset DP. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjHZolC4DpLJ"
      },
      "source": [
        "# Unbiased coin flip mean query\r\n",
        "# Returns result of DP data and true result\r\n",
        "def query(db):\r\n",
        "    true_result = torch.mean(db.float())\r\n",
        "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\r\n",
        "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\r\n",
        "\r\n",
        "    augmented_database = db.float()*first_coin_flip + (1-first_coin_flip)*second_coin_flip\r\n",
        "    db_result = torch.mean(augmented_database.float())*2 - 0.5 # Deskewing\r\n",
        "\r\n",
        "    return db_result, true_result"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So0Kf5nLtvHC"
      },
      "source": [
        "# query function with noise hyperparameter\r\n",
        "def query(db, noise=0.5):\r\n",
        "    true_result = torch.mean(db.float())\r\n",
        "    first_coin_flip = (torch.rand(len(db)) > noise).float()\r\n",
        "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\r\n",
        "\r\n",
        "    augmented_database = db.float()*first_coin_flip + (1-first_coin_flip)*second_coin_flip\r\n",
        "    skewed_result = augmented_database.float().mean()\r\n",
        "    private_result = ((skewed_result/noise)-0.5) * noise/(1-noise)\r\n",
        "\r\n",
        "    return private_result, true_result"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJikmRb7xBC",
        "outputId": "23d92324-b23f-449a-b21f-f356e508c8a7"
      },
      "source": [
        "noise_set = [(i+1)/10 for i in range(9)] #0.1, 0.2, ...\r\n",
        "database_size_set = [50, 100, 500, 1000]\r\n",
        "\r\n",
        "for noise in noise_set:\r\n",
        "    print('*******************************')\r\n",
        "    print('Setting noise as ', noise)\r\n",
        "    for database_size in database_size_set:\r\n",
        "        print('For size of dataset: ', database_size)\r\n",
        "        db, _ = helper.create_db_and_parallels(num_entries=database_size)\r\n",
        "        private_result, true_result = query(db, noise=noise)\r\n",
        "        print('Result with noise: ', private_result)\r\n",
        "        print('True Result: ', true_result)\r\n",
        "        print('................................')\r\n",
        "    print(' ')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************************\n",
            "Setting noise as  0.1\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.5889)\n",
            "True Result:  tensor(0.5600)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.5667)\n",
            "True Result:  tensor(0.5200)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4978)\n",
            "True Result:  tensor(0.5000)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4778)\n",
            "True Result:  tensor(0.4820)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.2\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.4250)\n",
            "True Result:  tensor(0.4800)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.4875)\n",
            "True Result:  tensor(0.4600)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4900)\n",
            "True Result:  tensor(0.4940)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4663)\n",
            "True Result:  tensor(0.4820)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.3\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.5000)\n",
            "True Result:  tensor(0.5200)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.3571)\n",
            "True Result:  tensor(0.4900)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.5314)\n",
            "True Result:  tensor(0.5060)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4743)\n",
            "True Result:  tensor(0.4760)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.4\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.4333)\n",
            "True Result:  tensor(0.4800)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.5333)\n",
            "True Result:  tensor(0.4800)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.5133)\n",
            "True Result:  tensor(0.5300)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4883)\n",
            "True Result:  tensor(0.5010)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.5\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.2600)\n",
            "True Result:  tensor(0.3600)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.4800)\n",
            "True Result:  tensor(0.5000)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4640)\n",
            "True Result:  tensor(0.4860)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.5380)\n",
            "True Result:  tensor(0.5090)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.6\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.7500)\n",
            "True Result:  tensor(0.4800)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.4000)\n",
            "True Result:  tensor(0.4900)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4400)\n",
            "True Result:  tensor(0.4840)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.5125)\n",
            "True Result:  tensor(0.5020)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.7\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.5000)\n",
            "True Result:  tensor(0.4800)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.4000)\n",
            "True Result:  tensor(0.4700)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4867)\n",
            "True Result:  tensor(0.4980)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.5500)\n",
            "True Result:  tensor(0.5180)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.8\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.)\n",
            "True Result:  tensor(0.5200)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.4000)\n",
            "True Result:  tensor(0.5300)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.4300)\n",
            "True Result:  tensor(0.4840)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4550)\n",
            "True Result:  tensor(0.4810)\n",
            "................................\n",
            " \n",
            "*******************************\n",
            "Setting noise as  0.9\n",
            "For size of dataset:  50\n",
            "Result with noise:  tensor(0.7000)\n",
            "True Result:  tensor(0.5800)\n",
            "................................\n",
            "For size of dataset:  100\n",
            "Result with noise:  tensor(0.)\n",
            "True Result:  tensor(0.4600)\n",
            "................................\n",
            "For size of dataset:  500\n",
            "Result with noise:  tensor(0.3600)\n",
            "True Result:  tensor(0.5180)\n",
            "................................\n",
            "For size of dataset:  1000\n",
            "Result with noise:  tensor(0.4700)\n",
            "True Result:  tensor(0.5090)\n",
            "................................\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJd1v9fk7-MG"
      },
      "source": [
        "## The more people participate in this, easier it gets to protect and increment the privacy of the people. Also easier it gets to learn from the people without violating the privacy of the participants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzBuE4Q18Bgb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}